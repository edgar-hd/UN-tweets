name: scrape_process_analyse

on:
  schedule:
    - cron: '00 13 * * *' # runs at 12:00 UTC everyday

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: checkout repo content
        uses: actions/checkout@v3 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v3
        with:
          python-version: '3.10.6' # install the python version needed
          
      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: execute py script # run proj1_script_live_collect_data.py to get the latest data
        # env: 
          # EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
          # EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          # EMAIL_RECIPIENT: ${{ secrets.EMAIL_RECIPIENT }}
        run: python proj1_script_live_collect_data.py
          
      - name: execute py script # run proj1_script_live_classify_sentiment.py to classify sentiment
        run: python proj1_script_live_classify_sentiment.py

      - name: execute py script # run proj1_analyse_live_tweets.py processing and analysis
        run: python proj1_analyse_live_tweets.py

      - name: commit files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "update data" -a
          
      - name: push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main  